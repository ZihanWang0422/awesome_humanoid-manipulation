## Whole Body Control

- [paper](https://arxiv.org/pdf/2502.01143) ASAP: Aligning Simulation and Real-World Physics for Learning Agile Humanoid Whole-Body Skills. [GitHub](https://github.com/LeCAR-Lab/ASAP) [website](https://agile.human2humanoid.com/)

- [paper](https://www.arxiv.org/pdf/2505.10918) OpenWBT: Open Whole-Body Teleoperation (OpenWBT) — Whole-body teleoperation and benchmarking tools. [GitHub](https://github.com/GalaxyGeneralRobotics/OpenWBT) [website](https://zzk273.github.io/R2S2/)


- [paper](https://arxiv.org/pdf/2504.21738) LangWBC: Language-conditioned Whole-Body Control — using language to specify whole-body robot behaviors. [GitHub](https://github.com/YiyangShao2003/LangWBC) [website](https://langwbc.github.io/)


- [paper](https://arxiv.org/pdf/2506.14770) GMT: General Motion Tracking for Humanoid Whole-Body Control. [GitHub](https://github.com/zixuan417/humanoid-general-motion-tracking) [website](https://gmt-humanoid.github.io/)

- [paper](https://arxiv.org/pdf/2506.12851) KungfuBot: Physics-Based Humanoid Whole-Body Control for Learning Highly-Dynamic Skills. [GitHub](https://github.com/TeleHuman/PBHC) [website](https://kungfu-bot.github.io/)

- [paper](https://arxiv.org/pdf/2402.16796) Expressive Whole-Body Control for Humanoid Robots. [GitHub](https://github.com/chengxuxin/expressive-humanoid) [website](https://expressive-humanoid.github.io/)

- HOVER: NVlabs HOVER project — whole-body humanoid research and tools. [GitHub](https://github.com/NVlabs/HOVER)

- [paper](https://arxiv.org/pdf/2508.08241) Whole-Body Tracking: Beyond Mimic — whole-body tracking and control methods. [GitHub](https://github.com/HybridRobotics/whole_body_tracking) [website](https://beyondmimic.github.io/)

- wb_humanoid_mpc: Whole-body model predictive control examples and code. [GitHub](https://github.com/manumerous/wb_humanoid_mpc)

## Mobile Manipulation



## Locomotion and Navigation

- Humanoid-Gym: Reinforcement Learning for Humanoid Robot with Zero-Shot Sim2Real Transfer. [website](https://sites.google.com/view/humanoid-gym/)/[GitHub](https://github.com/roboterax/humanoid-gym)

- [paper](https://arxiv.org/pdf/2212.03238) Walk these Ways: Tuning Robot Control for Generalization with Multiplicity of Behavior. [website](https://gmargo11.github.io/walk-these-ways/) [GitHub](https://github.com/Improbable-AI/walk-these-ways)


- [paper](https://arxiv.org/pdf/2203.15103) Adversarial Motion Priors Make Good Substitutes for Complex Reward Functions. [GitHub](https://github.com/escontra/AMP_for_hardware) [website](https://sites.google.com/berkeley.edu/amp-in-real/home)

- [paper](https://arxiv.org/pdf/2410.11825) Smooth Humanoid Locomotion with Lipschitz-Constrained Policies. [GitHub](https://github.com/zixuan417/smooth-humanoid-locomotion) [website](https://lipschitz-constrained-policy.github.io/)


## Manipulation

- [paper](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln) A curated list of state-of-the-art research in embodied AI, focusing on vision-language-action (VLA) models, vision-language navigation (VLN), and related multimodal learning approaches. [GitHub](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)





## Benchmark & Datasets

- Loco-MuJoCo: benchmark environments and tools for locomotion research. [GitHub](https://github.com/robfiras/loco-mujoco)

- [paper](https://arxiv.org/pdf/2403.10506) Humanoid-Bench: A benchmark suite for humanoid learning and evaluation. [GitHub](https://github.com/carlosferrazza/humanoid-bench) [website](https://humanoid-bench.github.io/)

- [paper](https://arxiv.org/pdf/1904.03278) AMASS: Archive of Motion Capture as Surface Shapes. [GitHub](https://github.com/nghorbani/amass) [website](https://amass.is.tue.mpg.de/)

- [paper](https://arxiv.org/pdf/2407.07788) BiGym: A Demo-Driven Mobile Bi-Manual Manipulation Benchmark. [GitHub](https://github.com/chernyadev/bigym) [website](https://chernyadev.github.io/bigym/)


## Simulation Tools

- Unitree MuJoCo: MuJoCo models and simulation code for Unitree robots. [GitHub](https://github.com/unitreerobotics/unitree_mujoco)

- Unitree RL Gym: reinforcement learning environments and wrappers for Unitree robots. [GitHub](https://github.com/unitreerobotics/unitree_rl_gym)

- Robot Lab: a collection of robot simulation and control experiments. [GitHub](https://github.com/fan-ziqi/robot_lab)

- MuJoCo Playground: example environments and experiments using MuJoCo (DeepMind). [GitHub](https://github.com/google-deepmind/mujoco_playground)

- RSL RL: reinforcement learning framework and environments from Legged Robotics. [GitHub](https://github.com/leggedrobotics/rsl_rl)

- Learning Humanoid Walking: implementations and experiments for learning humanoid walking. [GitHub](https://github.com/rohanpsingh/LearningHumanoidWalking)

- [paper](https://arxiv.org/pdf/2305.06456) PHC: Policy Homotopy Control — a method for policy morphing and sim-to-real in locomotion. [GitHub](https://github.com/ZhengyiLuo/PHC) [website](https://www.zhengyiluo.com/PHC-Site/)

- RL-SAR: reinforcement learning for sim-to-real and adaptive robotics. [GitHub](https://github.com/fan-ziqi/rl_sar)

- Humanoid Control: control algorithms and simulation code for humanoid robots. [GitHub](https://github.com/pocketxjl/humanoid-control)

- Unitree RL Lab: research and examples for reinforcement learning with Unitree robots. [GitHub](https://github.com/unitreerobotics/unitree_rl_lab)

- Cassie MuJoCo Sim: MuJoCo simulation and assets for Cassie. [GitHub](https://github.com/osudrl/cassie-mujoco-sim)
 
- DeepMimic: Physically simulated character control using deep reinforcement learning. [GitHub](https://github.com/xbpeng/DeepMimic)

- GMR: General Motion Retargeting / motion resources and tools. [GitHub](https://github.com/YanjieZe/GMR)





## Hardware Design

- Isaac Berkeley Humanoid: hardware and simulation assets for humanoid research. [GitHub](https://github.com/HybridRobotics/isaac_berkeley_humanoid)















